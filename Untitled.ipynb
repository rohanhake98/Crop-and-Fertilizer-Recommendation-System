{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4e5367-4d4e-4f15-ab44-5e71c2479025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (2200, 8)\n",
      "Dataset 2 shape: (8000, 9)\n",
      "\n",
      "Dataset 1 columns: ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label']\n",
      "Dataset 2 columns: ['Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous', 'Fertilizer Name']\n",
      "\n",
      "Unique crops in Dataset 1: 22\n",
      "Unique crops in Dataset 2: 11\n",
      "\n",
      "Fertilizer info shape: (77, 2)\n",
      "Number of common crops: 0\n",
      "\n",
      "Error during processing: No common crops found between datasets!\n",
      "Please check your input data and try again.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Load datasets with error handling\"\"\"\n",
    "    try:\n",
    "        # Dataset 1: Primary crop recommendation\n",
    "        df1 = pd.read_csv('Crop_recommendation.csv')  # N, P, K, temperature, humidity, ph, rainfall, label\n",
    "        \n",
    "        # Dataset 2: Fertilizer information\n",
    "        df2 = pd.read_csv('data_core.csv')  # Temparature, Humidity, Moisture, Soil Type, Crop Type, Nitrogen, Potassium, Phosphorous, Fertilizer Name\n",
    "        \n",
    "        print(\"Dataset 1 shape:\", df1.shape)\n",
    "        print(\"Dataset 2 shape:\", df2.shape)\n",
    "        print(\"\\nDataset 1 columns:\", df1.columns.tolist())\n",
    "        print(\"Dataset 2 columns:\", df2.columns.tolist())\n",
    "        \n",
    "        return df1, df2\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading datasets: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def preprocess_data(df1, df2):\n",
    "    \"\"\"Preprocess and merge the datasets with proper validation\"\"\"\n",
    "    # Clean dataset 1 (primary)\n",
    "    df1 = df1.rename(columns={'label': 'crop'})\n",
    "    print(\"\\nUnique crops in Dataset 1:\", df1['crop'].nunique())\n",
    "    \n",
    "    # Clean dataset 2 (fertilizer)\n",
    "    df2 = df2.rename(columns={\n",
    "        'Temparature': 'temperature',\n",
    "        'Phosphorous': 'P',\n",
    "        'Potassium': 'K',\n",
    "        'Nitrogen': 'N',\n",
    "        'Crop Type': 'crop',\n",
    "        'Moisture': 'moisture',\n",
    "        'Fertilizer Name': 'fertilizer'\n",
    "    })\n",
    "    print(\"Unique crops in Dataset 2:\", df2['crop'].nunique())\n",
    "    \n",
    "    # Get unique fertilizer recommendations per crop\n",
    "    fert_info = df2[['crop', 'fertilizer']].drop_duplicates()\n",
    "    print(\"\\nFertilizer info shape:\", fert_info.shape)\n",
    "    \n",
    "    # Find common crops between both datasets\n",
    "    common_crops = set(df1['crop'].unique()) & set(df2['crop'].unique())\n",
    "    print(\"Number of common crops:\", len(common_crops))\n",
    "    \n",
    "    if not common_crops:\n",
    "        raise ValueError(\"No common crops found between datasets!\")\n",
    "    \n",
    "    # Filter both datasets to only include common crops\n",
    "    df1 = df1[df1['crop'].isin(common_crops)]\n",
    "    fert_info = fert_info[fert_info['crop'].isin(common_crops)]\n",
    "    \n",
    "    # Merge with primary dataset\n",
    "    merged = df1.merge(fert_info, on='crop', how='left')\n",
    "    print(\"\\nMerged dataset shape:\", merged.shape)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values in merged data:\")\n",
    "    print(merged.isnull().sum())\n",
    "    \n",
    "    # Drop rows with missing fertilizer info if any\n",
    "    merged = merged.dropna(subset=['fertilizer'])\n",
    "    print(\"\\nFinal dataset shape after dropping NA:\", merged.shape)\n",
    "    \n",
    "    if merged.shape[0] == 0:\n",
    "        raise ValueError(\"Final dataset has no rows after processing!\")\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Load datasets\n",
    "df1, df2 = load_datasets()\n",
    "\n",
    "if df1 is None or df2 is None:\n",
    "    print(\"Could not load required datasets\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # Preprocess data\n",
    "    merged_data = preprocess_data(df1, df2)\n",
    "    \n",
    "    # Prepare features and targets\n",
    "    feature_cols = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "    target_col = 'crop'\n",
    "    fert_col = 'fertilizer'\n",
    "\n",
    "    X = merged_data[feature_cols]\n",
    "    y_crop = merged_data[target_col]\n",
    "    y_fert = merged_data[fert_col]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_crop_train, y_crop_test, y_fert_train, y_fert_test = train_test_split(\n",
    "        X, y_crop, y_fert, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "    print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "    # Create preprocessing pipeline for features\n",
    "    preprocessor = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Train crop recommendation model\n",
    "    crop_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    crop_model.fit(X_train, y_crop_train)\n",
    "\n",
    "    # Train fertilizer recommendation model\n",
    "    fert_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    fert_model.fit(X_train, y_fert_train)\n",
    "\n",
    "    # Evaluate models\n",
    "    print(\"\\nCrop Model Accuracy:\", crop_model.score(X_test, y_crop_test))\n",
    "    print(\"Fertilizer Model Accuracy:\", fert_model.score(X_test, y_fert_test))\n",
    "\n",
    "    # Save models\n",
    "    joblib.dump(crop_model, 'crop_model.pkl')\n",
    "    joblib.dump(fert_model, 'fertilizer_model.pkl')\n",
    "    print(\"\\nModels saved successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during processing: {e}\")\n",
    "    print(\"Please check your input data and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab32f6e5-9a72-4296-ba16-3568b985422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few crop names in Dataset 1: ['rice' 'maize' 'chickpea' 'kidneybeans' 'pigeonpeas' 'mothbeans'\n",
      " 'mungbean' 'blackgram' 'lentil' 'pomegranate']\n",
      "First few crop names in Dataset 2: ['Maize' 'Sugarcane' 'Cotton' 'Tobacco' 'Paddy' 'Barley' 'Wheat' 'Millets'\n",
      " 'Oil seeds' 'Pulses']\n",
      "\n",
      "Common standardized crops: {'cotton', 'rice', 'maize'}\n",
      "\n",
      "Final merged dataset shape: (2100, 10)\n",
      "Crop-fertilizer pairs:         crop fertilizer\n",
      "0       rice       Urea\n",
      "1       rice      28-28\n",
      "2       rice      20-20\n",
      "3       rice        DAP\n",
      "4       rice   14-35-14\n",
      "5       rice   10-26-26\n",
      "6       rice   17-17-17\n",
      "700    maize       Urea\n",
      "701    maize   17-17-17\n",
      "702    maize      28-28\n",
      "703    maize   14-35-14\n",
      "704    maize      20-20\n",
      "705    maize        DAP\n",
      "706    maize   10-26-26\n",
      "1400  cotton   14-35-14\n",
      "1401  cotton      20-20\n",
      "1402  cotton       Urea\n",
      "1403  cotton   17-17-17\n",
      "1404  cotton      28-28\n",
      "1405  cotton        DAP\n",
      "1406  cotton   10-26-26\n",
      "\n",
      "Training set size: 1680\n",
      "Test set size: 420\n",
      "\n",
      "Crop Model Accuracy: 1.0\n",
      "Fertilizer Model Accuracy: 0.0\n",
      "\n",
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Load datasets with error handling\"\"\"\n",
    "    try:\n",
    "        # Dataset 1: Primary crop recommendation\n",
    "        df1 = pd.read_csv('Crop_recommendation.csv')\n",
    "        \n",
    "        # Dataset 2: Fertilizer information\n",
    "        df2 = pd.read_csv('data_core.csv')\n",
    "        \n",
    "        print(\"\\nFirst few crop names in Dataset 1:\", df1['label'].unique()[:10])\n",
    "        print(\"First few crop names in Dataset 2:\", df2['Crop Type'].unique()[:10])\n",
    "        \n",
    "        return df1, df2\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading datasets: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def standardize_crop_names(name):\n",
    "    \"\"\"Standardize crop names for matching\"\"\"\n",
    "    name = str(name).strip().lower()\n",
    "    replacements = {\n",
    "        'rice': ['rice', 'paddy'],\n",
    "        'maize': ['maize', 'corn'],\n",
    "        'chickpea': ['chickpea', 'gram', 'chana'],\n",
    "        'kidneybeans': ['kidneybeans', 'rajma'],\n",
    "        'pigeonpeas': ['pigeonpeas', 'tur', 'arhar'],\n",
    "        'mothbeans': ['mothbeans', 'matki'],\n",
    "        'mungbean': ['mungbean', 'moong'],\n",
    "        'blackgram': ['blackgram', 'urad'],\n",
    "        'lentil': ['lentil', 'masoor'],\n",
    "        'cotton': ['cotton'],\n",
    "        'jute': ['jute']\n",
    "    }\n",
    "    \n",
    "    for standard_name, variants in replacements.items():\n",
    "        if name in variants:\n",
    "            return standard_name\n",
    "    return name\n",
    "\n",
    "def preprocess_data(df1, df2):\n",
    "    \"\"\"Preprocess and merge the datasets with crop name standardization\"\"\"\n",
    "    # Clean dataset 1\n",
    "    df1 = df1.rename(columns={'label': 'crop'})\n",
    "    df1['crop_std'] = df1['crop'].apply(standardize_crop_names)\n",
    "    \n",
    "    # Clean dataset 2\n",
    "    df2 = df2.rename(columns={\n",
    "        'Temparature': 'temperature',\n",
    "        'Phosphorous': 'P',\n",
    "        'Potassium': 'K',\n",
    "        'Nitrogen': 'N',\n",
    "        'Crop Type': 'crop',\n",
    "        'Fertilizer Name': 'fertilizer'\n",
    "    })\n",
    "    df2['crop_std'] = df2['crop'].apply(standardize_crop_names)\n",
    "    \n",
    "    # Get unique fertilizer recommendations per standardized crop\n",
    "    fert_info = df2[['crop_std', 'fertilizer']].drop_duplicates()\n",
    "    \n",
    "    # Find common crops between both datasets\n",
    "    common_crops = set(df1['crop_std'].unique()) & set(df2['crop_std'].unique())\n",
    "    print(\"\\nCommon standardized crops:\", common_crops)\n",
    "    \n",
    "    if not common_crops:\n",
    "        # Show all crops from both datasets for debugging\n",
    "        print(\"\\nAll crops in Dataset 1:\", df1['crop_std'].unique())\n",
    "        print(\"All crops in Dataset 2:\", df2['crop_std'].unique())\n",
    "        raise ValueError(\"No common crops found even after standardization!\")\n",
    "    \n",
    "    # Filter both datasets to only include common crops\n",
    "    df1 = df1[df1['crop_std'].isin(common_crops)]\n",
    "    fert_info = fert_info[fert_info['crop_std'].isin(common_crops)]\n",
    "    \n",
    "    # Merge with primary dataset\n",
    "    merged = df1.merge(fert_info, on='crop_std', how='left')\n",
    "    \n",
    "    # If still no matches, try fuzzy matching as last resort\n",
    "    if merged.shape[0] == 0:\n",
    "        print(\"\\nAttempting fuzzy matching...\")\n",
    "        from fuzzywuzzy import process\n",
    "        crop_mapping = {}\n",
    "        for crop in df1['crop_std'].unique():\n",
    "            match, score = process.extractOne(crop, df2['crop_std'].unique())\n",
    "            if score > 80:  # Only accept good matches\n",
    "                crop_mapping[crop] = match\n",
    "        print(\"Fuzzy matches found:\", crop_mapping)\n",
    "        \n",
    "        if crop_mapping:\n",
    "            df1['crop_mapped'] = df1['crop_std'].map(crop_mapping)\n",
    "            merged = df1.merge(\n",
    "                df2[['crop_std', 'fertilizer']].drop_duplicates(),\n",
    "                left_on='crop_mapped',\n",
    "                right_on='crop_std',\n",
    "                how='left'\n",
    "            )\n",
    "    \n",
    "    # Final check\n",
    "    if merged.shape[0] == 0:\n",
    "        raise ValueError(\"Final dataset has no rows after all matching attempts!\")\n",
    "    \n",
    "    print(\"\\nFinal merged dataset shape:\", merged.shape)\n",
    "    print(\"Crop-fertilizer pairs:\", merged[['crop', 'fertilizer']].drop_duplicates())\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Load datasets\n",
    "df1, df2 = load_datasets()\n",
    "\n",
    "if df1 is None or df2 is None:\n",
    "    print(\"Could not load required datasets\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # Preprocess data\n",
    "    merged_data = preprocess_data(df1, df2)\n",
    "    \n",
    "    # Prepare features and targets\n",
    "    feature_cols = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "    target_col = 'crop'\n",
    "    fert_col = 'fertilizer'\n",
    "\n",
    "    X = merged_data[feature_cols]\n",
    "    y_crop = merged_data[target_col]\n",
    "    y_fert = merged_data[fert_col]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_crop_train, y_crop_test, y_fert_train, y_fert_test = train_test_split(\n",
    "        X, y_crop, y_fert, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "    print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Train models\n",
    "    crop_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    crop_model.fit(X_train, y_crop_train)\n",
    "\n",
    "    fert_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    fert_model.fit(X_train, y_fert_train)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\nCrop Model Accuracy:\", crop_model.score(X_test, y_crop_test))\n",
    "    print(\"Fertilizer Model Accuracy:\", fert_model.score(X_test, y_fert_test))\n",
    "\n",
    "    # Save models\n",
    "    joblib.dump(crop_model, 'crop_model.pkl')\n",
    "    joblib.dump(fert_model, 'fertilizer_model.pkl')\n",
    "    print(\"\\nModels saved successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during processing: {e}\")\n",
    "    print(\"Please check your crop name mappings and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6851d5db-ba93-4bf7-80f4-f50ebf72fb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\rohan\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in c:\\users\\rohan\\anaconda3\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb36a7b-054c-42cb-a052-acbf9ae53a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1 crops: ['rice' 'maize' 'chickpea' 'kidneybeans' 'pigeonpeas' 'mothbeans'\n",
      " 'mungbean' 'blackgram' 'lentil' 'pomegranate' 'banana' 'mango' 'grapes'\n",
      " 'watermelon' 'muskmelon' 'apple' 'orange' 'papaya' 'coconut' 'cotton'\n",
      " 'jute' 'coffee']\n",
      "Dataset 2 crops: ['Maize' 'Sugarcane' 'Cotton' 'Tobacco' 'Paddy' 'Barley' 'Wheat' 'Millets'\n",
      " 'Oil seeds' 'Pulses' 'Ground Nuts']\n",
      "\n",
      "Final crop-fertilizer pairs:\n",
      "        crop mapped_crop fertilizer\n",
      "100    maize       Maize       Urea\n",
      "101    maize       Maize   17-17-17\n",
      "102    maize       Maize      28-28\n",
      "103    maize       Maize   14-35-14\n",
      "104    maize       Maize      20-20\n",
      "105    maize       Maize        DAP\n",
      "106    maize       Maize   10-26-26\n",
      "2500  cotton      Cotton   14-35-14\n",
      "2501  cotton      Cotton      20-20\n",
      "2502  cotton      Cotton       Urea\n",
      "2503  cotton      Cotton   17-17-17\n",
      "2504  cotton      Cotton      28-28\n",
      "2505  cotton      Cotton        DAP\n",
      "2506  cotton      Cotton   10-26-26\n",
      "\n",
      "Crop Model Accuracy: 1.0\n",
      "Fertilizer Model Accuracy: 0.0\n",
      "\n",
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Custom crop name mapping based on your datasets\n",
    "CROP_NAME_MAPPING = {\n",
    "    # Dataset 1 (Crop_recommendation) to Dataset 2 (data_core) mappings\n",
    "    'rice': 'Rice',\n",
    "    'maize': 'Maize',\n",
    "    'chickpea': 'Chickpea',\n",
    "    'kidneybeans': 'Kidney Beans',\n",
    "    'pigeonpeas': 'Pigeon Peas',\n",
    "    'mothbeans': 'Moth Beans',\n",
    "    'mungbean': 'Mung Bean',\n",
    "    'blackgram': 'Black Gram',\n",
    "    'lentil': 'Lentil',\n",
    "    'pomegranate': 'Pomegranate',\n",
    "    'banana': 'Banana',\n",
    "    'mango': 'Mango',\n",
    "    'grapes': 'Grapes',\n",
    "    'watermelon': 'Watermelon',\n",
    "    'muskmelon': 'Muskmelon',\n",
    "    'apple': 'Apple',\n",
    "    'orange': 'Orange',\n",
    "    'papaya': 'Papaya',\n",
    "    'coconut': 'Coconut',\n",
    "    'cotton': 'Cotton',\n",
    "    'jute': 'Jute',\n",
    "    'coffee': 'Coffee'\n",
    "}\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Load datasets with error handling\"\"\"\n",
    "    try:\n",
    "        # Dataset 1: Primary crop recommendation\n",
    "        df1 = pd.read_csv('Crop_recommendation.csv')\n",
    "        \n",
    "        # Dataset 2: Fertilizer information\n",
    "        df2 = pd.read_csv('data_core.csv')\n",
    "        \n",
    "        print(\"\\nDataset 1 crops:\", df1['label'].unique())\n",
    "        print(\"Dataset 2 crops:\", df2['Crop Type'].unique())\n",
    "        \n",
    "        return df1, df2\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading datasets: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def map_crop_names(df, mapping, source_col, target_col):\n",
    "    \"\"\"Map crop names between datasets using custom mapping\"\"\"\n",
    "    df[target_col] = df[source_col].str.lower().map(mapping)\n",
    "    unmapped = df[df[target_col].isna()][source_col].unique()\n",
    "    if len(unmapped) > 0:\n",
    "        print(f\"\\nUnmapped crops: {unmapped}\")\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df1, df2):\n",
    "    \"\"\"Preprocess and merge datasets with crop name mapping\"\"\"\n",
    "    # Clean dataset 1\n",
    "    df1 = df1.rename(columns={'label': 'crop'})\n",
    "    df1 = map_crop_names(df1, CROP_NAME_MAPPING, 'crop', 'mapped_crop')\n",
    "    \n",
    "    # Clean dataset 2\n",
    "    df2 = df2.rename(columns={\n",
    "        'Temparature': 'temperature',\n",
    "        'Phosphorous': 'P',\n",
    "        'Potassium': 'K',\n",
    "        'Nitrogen': 'N',\n",
    "        'Crop Type': 'crop',\n",
    "        'Fertilizer Name': 'fertilizer'\n",
    "    })\n",
    "    df2['mapped_crop'] = df2['crop']  # Already in standardized form\n",
    "    \n",
    "    # Get fertilizer info\n",
    "    fert_info = df2[['mapped_crop', 'fertilizer']].drop_duplicates()\n",
    "    \n",
    "    # Merge datasets\n",
    "    merged = df1.merge(fert_info, on='mapped_crop', how='left')\n",
    "    \n",
    "    # Drop rows without fertilizer info\n",
    "    merged = merged.dropna(subset=['fertilizer'])\n",
    "    \n",
    "    print(\"\\nFinal crop-fertilizer pairs:\")\n",
    "    print(merged[['crop', 'mapped_crop', 'fertilizer']].drop_duplicates())\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Main execution\n",
    "df1, df2 = load_datasets()\n",
    "\n",
    "if df1 is None or df2 is None:\n",
    "    print(\"Could not load required datasets\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    merged_data = preprocess_data(df1, df2)\n",
    "    \n",
    "    if merged_data.empty:\n",
    "        raise ValueError(\"No data remaining after merging - check crop name mappings\")\n",
    "    \n",
    "    # Prepare features and targets\n",
    "    feature_cols = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "    X = merged_data[feature_cols]\n",
    "    y_crop = merged_data['crop']\n",
    "    y_fert = merged_data['fertilizer']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_crop_train, y_crop_test, y_fert_train, y_fert_test = train_test_split(\n",
    "        X, y_crop, y_fert, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create pipeline\n",
    "    preprocessor = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Train models\n",
    "    crop_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    crop_model.fit(X_train, y_crop_train)\n",
    "    \n",
    "    fert_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    fert_model.fit(X_train, y_fert_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nCrop Model Accuracy:\", crop_model.score(X_test, y_crop_test))\n",
    "    print(\"Fertilizer Model Accuracy:\", fert_model.score(X_test, y_fert_test))\n",
    "    \n",
    "    # Save models\n",
    "    joblib.dump(crop_model, 'crop_model.pkl')\n",
    "    joblib.dump(fert_model, 'fertilizer_model.pkl')\n",
    "    print(\"\\nModels saved successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"Possible solutions:\")\n",
    "    print(\"1. Check the CROP_NAME_MAPPING dictionary matches your crop names\")\n",
    "    print(\"2. Verify both datasets contain compatible crops\")\n",
    "    print(\"3. Examine the unmapped crops list above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e08043-1564-4840-9087-153c3f69e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved models\n",
    "crop_model = joblib.load('crop_model.pkl')\n",
    "fert_model = joblib.load('fertilizer_model.pkl')\n",
    "\n",
    "print(\"Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d97be6-1c17-4098-bcb8-461f843ee860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_crop_recommendation(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    \"\"\"\n",
    "    Test the crop and fertilizer recommendation system\n",
    "    \n",
    "    Parameters:\n",
    "    N, P, K - Soil nutrients (mg/kg)\n",
    "    temperature - in °C\n",
    "    humidity - in %\n",
    "    ph - soil pH\n",
    "    rainfall - in mm\n",
    "    \"\"\"\n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame([[\n",
    "        N, P, K, temperature, humidity, ph, rainfall\n",
    "    ]], columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "    \n",
    "    # Get predictions\n",
    "    crop = crop_model.predict(input_data)[0]\n",
    "    fert = fert_model.predict(input_data)[0]\n",
    "    crop_probs = crop_model.predict_proba(input_data)[0]\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Recommended Crop: {crop}\")\n",
    "    print(f\"Recommended Fertilizer: {fert}\")\n",
    "    print(\"\\nAll Crop Probabilities:\")\n",
    "    for crop_name, prob in zip(crop_model.classes_, crop_probs):\n",
    "        print(f\"{crop_name}: {prob:.2%}\")\n",
    "    \n",
    "    return crop, fert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b7fd99b-701b-4d8d-bb2b-29ebbd766345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Crop: maize\n",
      "Recommended Fertilizer: 14-35-14\n",
      "\n",
      "All Crop Probabilities:\n",
      "cotton: 29.00%\n",
      "maize: 71.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('maize', '14-35-14')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example test (modify these values)\n",
    "test_crop_recommendation(\n",
    "    N=72,       # Nitrogen\n",
    "    P=45,       # Phosphorus\n",
    "    K=30,       # Potassium\n",
    "    temperature=28,   # °C\n",
    "    humidity=75,      # %\n",
    "    ph=6.5,           # pH\n",
    "    rainfall=1200     # mm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bca066-dff0-44ef-8194-c3a5b5b98faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c73ddee08fc49c992cf00293162e125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=72, description='Nitrogen (N):', max=140), IntSlider(value=45, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "\n",
    "# Create interactive widget\n",
    "interact(test_crop_recommendation,\n",
    "         N=widgets.IntSlider(min=0, max=140, value=72, description='Nitrogen (N):'),\n",
    "         P=widgets.IntSlider(min=0, max=145, value=45, description='Phosphorus (P):'),\n",
    "         K=widgets.IntSlider(min=0, max=205, value=30, description='Potassium (K):'),\n",
    "         temperature=widgets.FloatSlider(min=0, max=50, value=28, description='Temp (°C):'),\n",
    "         humidity=widgets.FloatSlider(min=0, max=100, value=75, description='Humidity (%):'),\n",
    "         ph=widgets.FloatSlider(min=3, max=10, value=6.5, description='Soil pH:'),\n",
    "         rainfall=widgets.FloatSlider(min=0, max=3000, value=1200, description='Rainfall (mm):')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "796facc6-7f25-42be-a862-5a4672792c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Case 1:\n",
      "Recommended Crop: maize\n",
      "Recommended Fertilizer: 14-35-14\n",
      "\n",
      "All Crop Probabilities:\n",
      "cotton: 29.00%\n",
      "maize: 71.00%\n",
      "\n",
      "Test Case 2:\n",
      "Recommended Crop: maize\n",
      "Recommended Fertilizer: DAP\n",
      "\n",
      "All Crop Probabilities:\n",
      "cotton: 1.00%\n",
      "maize: 99.00%\n"
     ]
    }
   ],
   "source": [
    "# Create test cases\n",
    "test_cases = [\n",
    "    {'N':72, 'P':45, 'K':30, 'temperature':28, 'humidity':75, 'ph':6.5, 'rainfall':1200},\n",
    "    {'N':80, 'P':50, 'K':40, 'temperature':25, 'humidity':60, 'ph':7.0, 'rainfall':800},\n",
    "    # Add more test cases as needed\n",
    "]\n",
    "\n",
    "# Test all cases\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    test_crop_recommendation(**case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442d35d0-64f9-45d4-9197-32ebcfdb6f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".recommendation-card {\n",
       "    padding: 20px;\n",
       "    background: #f5f5f5;\n",
       "    border-radius: 10px;\n",
       "    margin: 10px 0;\n",
       "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
       "}\n",
       ".crop-name {\n",
       "    font-size: 24px;\n",
       "    color: #2E7D32;\n",
       "    font-weight: bold;\n",
       "    margin-bottom: 10px;\n",
       "}\n",
       ".fertilizer {\n",
       "    font-size: 18px;\n",
       "    color: #1565C0;\n",
       "    margin-bottom: 15px;\n",
       "}\n",
       ".probability-bar {\n",
       "    height: 20px;\n",
       "    background: #e0e0e0;\n",
       "    border-radius: 10px;\n",
       "    margin: 5px 0;\n",
       "    overflow: hidden;\n",
       "}\n",
       ".probability-fill {\n",
       "    height: 100%;\n",
       "    background: #4CAF50;\n",
       "    border-radius: 10px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style='color:#2E7D32; text-align:center'>🌾 Smart Crop Recommender</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b311d38dd741d9ab906da41c3b82f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=72.0, description='Nitrogen (N):', max=140.0, style=SliderStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc6cef8b81f45da9ce7e7ff03150fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4071277a416a46538c0924a7f2234d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    crop_model = joblib.load('crop_model.pkl')\n",
    "    fert_model = joblib.load('fertilizer_model.pkl')\n",
    "    print(\"✅ Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading models: {e}\")\n",
    "\n",
    "# Create input widgets with improved layout\n",
    "soil_box = widgets.VBox([\n",
    "    widgets.FloatSlider(min=0, max=140, value=72, description='Nitrogen (N):', style={'description_width': '100px'}),\n",
    "    widgets.FloatSlider(min=0, max=145, value=45, description='Phosphorus (P):', style={'description_width': '100px'}),\n",
    "    widgets.FloatSlider(min=0, max=205, value=30, description='Potassium (K):', style={'description_width': '100px'}),\n",
    "    widgets.FloatSlider(min=3, max=10, value=6.5, step=0.1, description='Soil pH:', style={'description_width': '100px'})\n",
    "])\n",
    "\n",
    "env_box = widgets.VBox([\n",
    "    widgets.FloatSlider(min=0, max=50, value=28, description='Temperature (°C):', style={'description_width': '150px'}),\n",
    "    widgets.FloatSlider(min=0, max=100, value=75, description='Humidity (%):', style={'description_width': '150px'}),\n",
    "    widgets.FloatSlider(min=0, max=3000, value=1200, step=50, description='Rainfall (mm):', style={'description_width': '150px'})\n",
    "])\n",
    "\n",
    "input_ui = widgets.HBox([soil_box, env_box])\n",
    "\n",
    "# Create output areas\n",
    "recommendation_output = widgets.Output()\n",
    "probability_chart = widgets.Output()\n",
    "\n",
    "# Style for output\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".recommendation-card {\n",
    "    padding: 20px;\n",
    "    background: #f5f5f5;\n",
    "    border-radius: 10px;\n",
    "    margin: 10px 0;\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "}\n",
    ".crop-name {\n",
    "    font-size: 24px;\n",
    "    color: #2E7D32;\n",
    "    font-weight: bold;\n",
    "    margin-bottom: 10px;\n",
    "}\n",
    ".fertilizer {\n",
    "    font-size: 18px;\n",
    "    color: #1565C0;\n",
    "    margin-bottom: 15px;\n",
    "}\n",
    ".probability-bar {\n",
    "    height: 20px;\n",
    "    background: #e0e0e0;\n",
    "    border-radius: 10px;\n",
    "    margin: 5px 0;\n",
    "    overflow: hidden;\n",
    "}\n",
    ".probability-fill {\n",
    "    height: 100%;\n",
    "    background: #4CAF50;\n",
    "    border-radius: 10px;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "def update_recommendation(N, P, K, ph, temp, humidity, rainfall):\n",
    "    with recommendation_output:\n",
    "        recommendation_output.clear_output(wait=True)\n",
    "        \n",
    "        # Prepare input data\n",
    "        input_data = pd.DataFrame([[\n",
    "            N, P, K, temp, humidity, ph, rainfall\n",
    "        ]], columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "        \n",
    "        # Get predictions\n",
    "        crop = crop_model.predict(input_data)[0]\n",
    "        fert = fert_model.predict(input_data)[0]\n",
    "        probs = crop_model.predict_proba(input_data)[0]\n",
    "        \n",
    "        # Get top 5 crops\n",
    "        top5_idx = probs.argsort()[-5:][::-1]\n",
    "        top5_crops = crop_model.classes_[top5_idx]\n",
    "        top5_probs = probs[top5_idx]\n",
    "        \n",
    "        # Create recommendation display\n",
    "        display(HTML(f\"\"\"\n",
    "        <div class='recommendation-card'>\n",
    "            <div class='crop-name'>🌱 Best Crop: {crop}</div>\n",
    "            <div class='fertilizer'>🧪 Recommended Fertilizer: {fert}</div>\n",
    "            <div style='margin-top:15px; font-weight:bold'>Top 5 Suitable Crops:</div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        # Display probability bars\n",
    "        with probability_chart:\n",
    "            probability_chart.clear_output(wait=True)\n",
    "            \n",
    "            plt.figure(figsize=(8, 4))\n",
    "            colors = plt.cm.Greens(np.linspace(0.4, 1, len(top5_crops)))\n",
    "            bars = plt.barh(top5_crops[::-1], top5_probs[::-1]*100, color=colors)\n",
    "            \n",
    "            plt.xlabel('Probability (%)')\n",
    "            plt.title('Crop Suitability')\n",
    "            plt.xlim(0, 100)\n",
    "            plt.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                plt.text(width-5 if width > 10 else width+2, \n",
    "                         bar.get_y() + bar.get_height()/2, \n",
    "                         f'{width:.1f}%', \n",
    "                         ha='left' if width <= 10 else 'right', \n",
    "                         va='center',\n",
    "                         color='white' if width > 50 else 'black')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Link widgets to update function\n",
    "def on_value_change(change):\n",
    "    update_recommendation(\n",
    "        soil_box.children[0].value,\n",
    "        soil_box.children[1].value,\n",
    "        soil_box.children[2].value,\n",
    "        soil_box.children[3].value,\n",
    "        env_box.children[0].value,\n",
    "        env_box.children[1].value,\n",
    "        env_box.children[2].value\n",
    "    )\n",
    "\n",
    "for widget in soil_box.children + env_box.children:\n",
    "    widget.observe(on_value_change, names='value')\n",
    "\n",
    "# Initial display\n",
    "display(HTML(\"<h1 style='color:#2E7D32; text-align:center'>🌾 Smart Crop Recommender</h1>\"))\n",
    "display(input_ui)\n",
    "display(recommendation_output)\n",
    "display(probability_chart)\n",
    "\n",
    "# Trigger initial update\n",
    "on_value_change(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dba690-7931-4007-b8c6-cf275170ff2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
